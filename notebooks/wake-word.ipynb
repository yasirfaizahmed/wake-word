{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd07edac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa, numpy as np\n",
    "import pathlib as p\n",
    "from matplotlib import pyplot as plt\n",
    "import soundfile as sf\n",
    "from ww_config.paths import *\n",
    "from ww_config.config import *\n",
    "import random\n",
    "from scipy.signal import fftconvolve\n",
    "import librosa.display\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6f99d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some dir creations\n",
    "if not RECORDINGS_PATH.exists():\n",
    "  RECORDINGS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "WAKE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "WAKE_CHOPPED.mkdir(parents=True, exist_ok=True)\n",
    "WAKE_AUGMENTED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "NON_WAKE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "NON_WAKE_CHOPPED_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a713bf6f",
   "metadata": {},
   "source": [
    "### non-wake word data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f857a6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_wake_mfcc = []\n",
    "# no_of_plots = 30\n",
    "sub_folder = NON_WAKE\n",
    "\n",
    "chop_duration = 2   # every 2 seconds\n",
    "file_count = 0\n",
    "chop_length = chop_duration * SAMPLE_RATE   # no. of samples per chop\n",
    "for file in p.Path.joinpath(RECORDINGS_PATH, sub_folder).glob(\"*\"):\n",
    "  y, sr = librosa.load(file, sr=SAMPLE_RATE)\n",
    " \n",
    "  for i, chop_number in enumerate(range(int(y.shape[0]//chop_length))):\n",
    "    filename = NON_WAKE_CHOPPED_DIR.joinpath(f\"chopped_wake{file_count}.wav\")\n",
    "    sf.write(filename, y[i*chop_length:(i+1)*chop_length], sr)\n",
    "    mfcc = librosa.feature.mfcc(y=y[i*chop_length:(i+1)*chop_length], sr=sr, n_mfcc=N_MFCC)\n",
    "    non_wake_mfcc.append(mfcc)  \n",
    "    file_count += 1\n",
    "    print(f\"Chopped original into multiples of {chop_duration} seconds and saved at {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eb005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 10))\n",
    "librosa.display.specshow(non_wake_mfcc[0], sr=SAMPLE_RATE, x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title(\"MFCCs\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"MFCC Coefficients\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c633d2b7",
   "metadata": {},
   "source": [
    "### wake word data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb29387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wake_mfcc = []\n",
    "# no_of_plots = 30\n",
    "sub_folder = WAKE\n",
    "N_MFCC=20   # number of features\n",
    "\n",
    "chop_duration = 2   # first 2 seconds only\n",
    "i = 0\n",
    "for file in p.Path.joinpath(RECORDINGS_PATH, sub_folder).glob(\"*\"):\n",
    "  y, sr = librosa.load(file, sr=SAMPLE_RATE)\n",
    "\n",
    "  filename = WAKE_CHOPPED.joinpath(f\"chopped_wake{i}.wav\")\n",
    "  sf.write(filename, y[:chop_length], sr)\n",
    "  mfcc = librosa.feature.mfcc(y=y[:chop_length], sr=sr, n_mfcc=N_MFCC)\n",
    "  wake_mfcc.append(mfcc)\n",
    "  i += 1\n",
    "  print(f\"Chopped first {chop_duration} seconds and saved at {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bbd10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.specshow(wake_mfcc[1], sr=SAMPLE_RATE, x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title(\"MFCCs\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"MFCC Coefficients\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1fd9a5",
   "metadata": {},
   "source": [
    "### Augmentation of wake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed87929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to augment the chopped wake samples due to low in count\n",
    "# Definig some Augmentation utility methods\n",
    "\n",
    "def random_gain(y, min_db=-6, max_db=6):\n",
    "  db = random.uniform(min_db, max_db)\n",
    "  gain = 10.0 ** (db / 20.0)\n",
    "  return y * gain\n",
    "\n",
    "def add_background(y, bg, snr_db):\n",
    "  # adjust background to desired snr relative to signal RMS\n",
    "  rms_signal = np.sqrt(np.mean(y**2)) + 1e-9\n",
    "  rms_bg = np.sqrt(np.mean(bg**2)) + 1e-9\n",
    "  # compute linear scaling for bg\n",
    "  snr_linear = 10 ** (snr_db / 20.0)\n",
    "  scale = (rms_signal / (snr_linear * rms_bg))\n",
    "  bg_scaled = bg * scale\n",
    "  # trim or pad bg to match length\n",
    "  if len(bg_scaled) >= len(y):\n",
    "    start = random.randint(0, len(bg_scaled) - len(y))\n",
    "    bg_segment = bg_scaled[start:start+len(y)]\n",
    "  else:\n",
    "    # repeat bg to fill\n",
    "    repeats = int(np.ceil(len(y) / len(bg_scaled)))\n",
    "    bg_tiled = np.tile(bg_scaled, repeats)[:len(y)]\n",
    "    bg_segment = bg_tiled\n",
    "  return y + bg_segment\n",
    "\n",
    "def time_stretch(y, low=0.9, high=1.1):\n",
    "  rate = random.uniform(low, high)\n",
    "  # librosa time_stretch expects magnitude STFT -> use effects.time_stretch on waveform via resampling workaround:\n",
    "  try:\n",
    "    y_stretched = librosa.effects.time_stretch(y, rate)\n",
    "  except Exception:\n",
    "    # fallback: resample (this will change pitch)\n",
    "    new_len = int(len(y) / rate)\n",
    "    y_stretched = librosa.resample(y, orig_sr=SAMPLE_RATE, target_sr=int(SAMPLE_RATE*rate))\n",
    "    y_stretched = librosa.resample(y_stretched, orig_sr=int(SAMPLE_RATE*rate), target_sr=SAMPLE_RATE)\n",
    "  return y_stretched\n",
    "\n",
    "def pitch_shift(y, semitones_low=-2, semitones_high=2):\n",
    "  n_steps = random.uniform(semitones_low, semitones_high)\n",
    "  return librosa.effects.pitch_shift(y, sr=SAMPLE_RATE, n_steps=n_steps)\n",
    "\n",
    "def time_shift(y, max_shift_seconds=0.15):\n",
    "  max_shift = int(max_shift_seconds * SAMPLE_RATE)\n",
    "  shift = random.randint(-max_shift, max_shift)\n",
    "  if shift == 0:\n",
    "    return y\n",
    "  if shift > 0:\n",
    "    return np.pad(y, (shift, 0), mode='constant')[:len(y)]\n",
    "  else:\n",
    "    return np.pad(y, (0, -shift), mode='constant')[-shift:len(y)-shift]\n",
    "\n",
    "def add_reverb(y, reverb_scale=0.3):\n",
    "  # simple exponential impulse response\n",
    "  ir_len = int(0.03 * SAMPLE_RATE)  # 30 ms IR\n",
    "  t = np.arange(ir_len) / SAMPLE_RATE\n",
    "  decay = np.exp(-t * (1.0 + random.random()*10.0))  # random decay rate\n",
    "  ir = decay\n",
    "  ir = ir / np.sum(np.abs(ir))\n",
    "  y_rev = fftconvolve(y, ir)[:len(y)]\n",
    "  return y * (1 - reverb_scale) + y_rev * reverb_scale\n",
    "\n",
    "def random_filter(y):\n",
    "  # light low-pass / high-pass via simple FFT mask\n",
    "  # For simplicity use librosa.effects.preemphasis as a proxy\n",
    "  if random.random() < 0.2:\n",
    "    return librosa.effects.preemphasis(y)\n",
    "  return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa97357",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load backgrounds into memory for speed\n",
    "bg_files = [os.path.join(NON_WAKE_DIR, f) for f in os.listdir(NON_WAKE_DIR) if f.endswith(\".wav\")]\n",
    "bg_sigs = []\n",
    "for p in bg_files:\n",
    "    bg, _ = librosa.load(p, sr=SAMPLE_RATE, mono=True)\n",
    "    bg_sigs.append(bg)\n",
    "\n",
    "wake_files = [os.path.join(WAKE_DIR, f) for f in os.listdir(WAKE_DIR) if f.endswith(\".wav\")]\n",
    "\n",
    "file_count = 0\n",
    "for wf in wake_files:\n",
    "    y, _ = librosa.load(wf, sr=SAMPLE_RATE, mono=True)\n",
    "    # optional: trim silence\n",
    "    y, _ = librosa.effects.trim(y, top_db=30)\n",
    "    for i in range(N_AUG_PER_FILE):\n",
    "        y_aug = y.copy()\n",
    "        # order: small random transforms\n",
    "        if random.random() < 0.6:\n",
    "            y_aug = time_stretch(y_aug, 0.92, 1.08)\n",
    "        if random.random() < 0.6:\n",
    "            y_aug = pitch_shift(y_aug, -1.5, 1.5)\n",
    "        if random.random() < 0.7:\n",
    "            y_aug = time_shift(y_aug, max_shift_seconds=0.12)\n",
    "        if random.random() < 0.8:\n",
    "            y_aug = random_gain(y_aug, -6, 6)\n",
    "        if random.random() < 0.7 and len(bg_sigs) > 0:\n",
    "            bg = random.choice(bg_sigs)\n",
    "            snr = random.uniform(0, 20)  # 0 dB to 20 dB\n",
    "            y_aug = add_background(y_aug, bg, snr_db=snr)\n",
    "        if random.random() < 0.3:\n",
    "            y_aug = add_reverb(y_aug, reverb_scale=random.uniform(0.05, 0.35))\n",
    "        y_aug = random_filter(y_aug)\n",
    "        # normalize to avoid clipping\n",
    "        max_abs = np.max(np.abs(y_aug)) + 1e-9\n",
    "        if max_abs > 1.0:\n",
    "            y_aug = y_aug / max_abs * 0.99\n",
    "        out_path = os.path.join(WAKE_AUGMENTED_DIR, f\"aug_{file_count}.wav\")\n",
    "        sf.write(out_path, y_aug, SAMPLE_RATE)\n",
    "        file_count += 1\n",
    "\n",
    "print(f\"Created {file_count} augmented files in {WAKE_AUGMENTED_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a239d9",
   "metadata": {},
   "source": [
    "### Forming the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff0087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file):\n",
    "  y, _ = librosa.load(file, sr=SAMPLE_RATE)\n",
    "  mfcc = librosa.feature.mfcc(y=y, sr=SAMPLE_RATE, n_mfcc=N_MFCC)\n",
    "  mfcc = mfcc.T\n",
    "  if len(mfcc) < MAX_LEN:\n",
    "    pad = np.zeros((MAX_LEN - len(mfcc)), N_MFCC)\n",
    "    mfcc = np.vstack([mfcc, pad])\n",
    "  else:\n",
    "    mfcc = mfcc[:MAX_LEN]\n",
    "  return mfcc\n",
    "\n",
    "# wake data\n",
    "wake_data = []\n",
    "for file in WAKE_AUGMENTED_DIR.glob(\"*\"):\n",
    "  wake_data.append(extract_features(file))\n",
    "\n",
    "# non-wake data\n",
    "non_wake_data = []\n",
    "for file in NON_WAKE_CHOPPED_DIR.glob(\"*\"):\n",
    "  non_wake_data.append(extract_features(file))\n",
    "\n",
    "\n",
    "class WakeWordDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, X, y):\n",
    "    self.X = [torch.tensor(x, dtype=torch.float32) for x in X]\n",
    "    self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.X[index], self.y[index]\n",
    "\n",
    "wake_word_dataset = WakeWordDataset(X=wake_data + non_wake_data, y=[1 for _ in range(len(wake_data))] + [0 for _ in range(len(non_wake_data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4bb2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(wake_word_dataset), wake_word_dataset.X[0].shape)\n",
    "print(wake_word_dataset.y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f25553",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aa76b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WakeWord(torch.nn.Module):\n",
    "  def __init__(self, input_size: int, hidden_size: int, output_size: int):\n",
    "    super().__init__()\n",
    "    self.lstm = torch.nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
    "    self.fc1 = torch.nn.Linear(in_features=hidden_size, out_features=output_size)\n",
    "\n",
    "  def forward(self, input_data):\n",
    "    lstm_output, _ = self.lstm(input_data)\n",
    "    output = torch.nn.functional.sigmoid(self.fc1(lstm_output[:, -1, :]))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e93615",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WakeWord(input_size=N_MFCC, hidden_size=32, output_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8be04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset=wake_word_dataset, batch_size=10, num_workers=1)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a91f87",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1861d792",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "loss_per_epoch = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  train_loss_per_batch = 0\n",
    "  model.train()\n",
    "  for batch_count, (input_data, labels) in enumerate(dataloader):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(input_data)\n",
    "\n",
    "    loss = criterion(outputs, labels.view(-1, 1).float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss_per_batch += loss.item()\n",
    "  loss_per_epoch.append(train_loss_per_batch/batch_count)\n",
    "  print(f\"Training loss per epoch: {train_loss_per_batch/batch_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cf4892",
   "metadata": {},
   "source": [
    "### Validating inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bca1675e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wake word probability: 0.64\n"
     ]
    }
   ],
   "source": [
    "mfcc = extract_features(\"/home/xd/Documents/wake-word/.data/val/wake.wav\")\n",
    "mfcc = torch.tensor(mfcc, dtype=torch.float32)\n",
    "mfcc = mfcc.unsqueeze(0).float()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  prob = model(mfcc).item()\n",
    "\n",
    "print(f\"Wake word probability: {prob:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
